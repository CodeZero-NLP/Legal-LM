{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Flow Between Agents\n",
    "\n",
    "The system's data flow is coordinated by the Task Planner Agent:\n",
    "\n",
    "1. Initial Flow: Document → Task Planner → Pre-processor\n",
    "2. Information Extraction: Pre-processor → Context Bank & Task Planner\n",
    "3. Knowledge Gathering: Task Planner → Knowledge Agent → Context Bank & Task Planner\n",
    "4. Compliance Analysis: Task Planner → Compliance Checker (accessing Context Bank)\n",
    "   - If knowledge is insufficient → Knowledge Agent (with the missing fields)\n",
    "   - If knowledge is sufficient → Check compliance for each clause\n",
    "5. Conditional Processing:\n",
    "   - If contradictions: Compliance Checker → Clause Rewriter → Compliance Checker\n",
    "   - If compliant: Compliance Checker → Task Planner\n",
    "6. Summarizing Changes: Task Planner → Post-processor\n",
    "7. Task Completion: Post-processor → Final Output → User\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_swarm import create_handoff_tool, create_swarm\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from agents.utils.ollama_client import OllamaClient\n",
    "from agents.utils.api_client import APIClient\n",
    "from typing import Any, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SETUP] Tavily API Key loaded successfully.\n",
      "[SETUP] Initialized ChatGoogleGenerativeAI model with gemini-2.0-flash\n",
      "[SETUP] Initialized GoogleGenerativeAIEmbeddings model\n"
     ]
    }
   ],
   "source": [
    "# model = ChatOllama(model=\"llama3.1:latest\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "if not tavily_api_key:\n",
    "    raise ValueError(\"TAVILY_API_KEY not found in environment variables. Please set it in your .env file.\")\n",
    "\n",
    "print(\"[SETUP] Tavily API Key loaded successfully.\")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.1,\n",
    "    google_api_key=google_api_key\n",
    ")\n",
    "print(\"[SETUP] Initialized ChatGoogleGenerativeAI model with gemini-2.0-flash\")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=google_api_key\n",
    ")\n",
    "print(\"[SETUP] Initialized GoogleGenerativeAIEmbeddings model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM client to be used by tools\n",
    "\n",
    "def _initialize_llm_client(use_ollama: bool, model_name: str) -> Any:\n",
    "    \"\"\"Initialize and return the appropriate LLM client based on settings.\"\"\"\n",
    "    try:\n",
    "        if use_ollama:\n",
    "            print(f\"[SETUP] Initializing Ollama client with model {model_name}\")\n",
    "            return OllamaClient(model_name)\n",
    "        else:\n",
    "            print(f\"[SETUP] Initializing API client with model {model_name}\")\n",
    "            return APIClient(model_name)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to initialize LLM client: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Bank Initialization\n",
    "\n",
    "Initialize a shared context bank instance that will be used by all agents to store and retrieve document information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_bank import ContextBank\n",
    "\n",
    "# Initialize a single shared context bank instance\n",
    "context_bank = ContextBank()\n",
    "\n",
    "# This context_bank will be passed to all agents that need to store or retrieve information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent_tools = [\n",
    "    create_handoff_tool(agent_name=\"Pre Processor Agent\", description=\"Transfer when pre-processing is needed, it helps to format and clean the input data.\"),\n",
    "    create_handoff_tool(agent_name=\"Knowledge Agent\", description=\"Transfer when knowledge is needed, it helps to retrieve knowledge from the web using websearcher.\"),\n",
    "    create_handoff_tool(agent_name=\"Compliance Checker Agent\", description=\"Transfer when compliance checking is needed, it helps to check legal documents for compliance with regulations.\"),\n",
    "    create_handoff_tool(agent_name=\"Post Processor Agent\", description=\"Transfer when post processing is needed, it helps to format and finalize the output.\"),\n",
    "]\n",
    "\n",
    "planner_agent_node = create_react_agent(\n",
    "    model,\n",
    "    planner_agent_tools,\n",
    "    prompt=\"\"\"\n",
    "        You are a Task Planner Agent responsible for coordinating a multi-agent system to analyze legal documents for discrepancies and compliance. Your job is to plan and delegate tasks to specialized agents using the relevant handoff tools and track task completion.\n",
    "\n",
    "        INPUTS:\n",
    "        Problem to solve: use the user prompt\n",
    "        Analyze a legal document for discrepancies and compliance issues.\n",
    "\n",
    "        PLANNED TASKS:\n",
    "\n",
    "        * Preprocess document\n",
    "        * Extract and classify clauses\n",
    "        * Retrieve relevant legal compliance knowledge from the web\n",
    "        * Check clause compliance and legal discrepancies\n",
    "        * Summarize issues and finalize output\n",
    "\n",
    "        AVAILABLE AGENTS:\n",
    "        * Pre Processor Agent: Responsible for pre-processing the document, extracting clauses, and classifying them. Processes the input legal document, adds all the relevant information to the context bank and returns status.\n",
    "        * Knowledge Agent: Responsible for retrieving relevant legal compliance knowledge from the web. Fetches information from the web, adds all the relevant knowledge to a vector DB and returns status.\n",
    "        * Compliance Checker Agent: Responsible for checking the compliance of clauses with legal regulations. Performs the compliance check, returns a list of non-compliant clauses and their details. Also returns status.\n",
    "        * Post Processor Agent: Responsible for summarizing issues and finalizing the output. Formats the final output and returns a summary of the compliance check results. Also returns status.\n",
    "\n",
    "        ACTION: \n",
    "        [IMPORTANT] Status Check - Check status of Preprocessor, Compliance Checker, and Post-Processor agents\n",
    "\n",
    "        If Preprocessor status is not complete, trigger Preprocessor Agent.\n",
    "        Once preprocessing is complete, trigger Knowledge Agent.\n",
    "        After Knowledge Agent retrieves relevant knowledge, trigger Compliance Checker Agent.\n",
    "        After completing clause compliance check, Post Processor Agent is triggered for final output and summary.\n",
    "\n",
    "        Rationale:\n",
    "        [IMPORTANT] Do not stop the workflow at any intermediate step. Always proceed till the final step, i.e., using the Post Processor Agent to generate the final summary for the user.\n",
    "        [EXTREMELY CRITICAL] Each agent’s task is sequentially dependent, ensure no step is skipped in the workflow. Status check ensures no redundant computation and completion of workflow.\n",
    "    \"\"\",\n",
    "    name=\"Planner Agent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "[SETUP] Loaded spaCy NER model en_core_web_sm\n",
      "[SETUP] Initializing API client with model gemini-2.0-flash\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import spacy\n",
    "import uuid\n",
    "import spacy\n",
    "import json  # Added for pretty printing\n",
    "from agents.compliance_checker import _estimate_jurisdiction\n",
    "\n",
    "# Download the spaCy model if it's not already installed\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# Load once to avoid redundant loading\n",
    "spacy_ner = spacy.load(\"en_core_web_sm\")\n",
    "print(\"[SETUP] Loaded spaCy NER model en_core_web_sm\")\n",
    "\n",
    "llm_client = _initialize_llm_client(use_ollama=False, model_name=\"gemini-2.0-flash\")\n",
    "\n",
    "# TODO : Update the context bank with the clauses, jurisdiction and the document type/metadata\n",
    "\n",
    "def preprocess_document_tool_implementation(file_path: str, system_prompt) -> dict:\n",
    "    \"\"\"\n",
    "    Consolidated preprocessing tool to be used as a callable function in a multi-agent system.\n",
    "    Extracts text, title, named entities, and clause classifications from a PDF document.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"[PREPROCESS] Starting document preprocessing for: {file_path}\")\n",
    "    # print(f\"[PREPROCESS] Context Bank state at start: {json.dumps(context_bank.get_all(), indent=2)}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    # Step 1: Extract text from PDF\n",
    "    print(\"[PREPROCESS] Step 1: Extracting text from PDF...\")\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\".join(page.extract_text() for page in reader.pages)\n",
    "    print(f\"[PREPROCESS] Extracted {len(text)} characters of text\")\n",
    "\n",
    "    print(\"[PREPROCESS] Step 2: Extracting title...\")\n",
    "    title_query = \"what is the title of this document?\" + text[:1000]\n",
    "    title = llm_client.query(title_query)\n",
    "    print(f\"[PREPROCESS] Extracted title: {title}\")\n",
    "\n",
    "    # Step 3: Named Entity Recognition\n",
    "    print(\"[PREPROCESS] Step 3: Performing Named Entity Recognition...\")\n",
    "    doc = spacy_ner(text)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.text, ent.label_))\n",
    "    print(f\"[PREPROCESS] Extracted {len(entities)} named entities\")\n",
    "    print(f\"[PREPROCESS] Sample entities (first 5): {entities[:5]}\")\n",
    "\n",
    "    # Step 4: Document + Clause Classification via external LLM system\n",
    "    print(\"[PREPROCESS] Step 4: Classifying document and clauses...\")\n",
    "    llm_output = llm_client.query(text, system_prompt)\n",
    "\n",
    "    if isinstance(llm_output, str):\n",
    "        # strip any enclosing backticks (```), whitespace, etc.\n",
    "        llm_output = llm_output.strip().strip(\"```json\").strip(\"`\")\n",
    "        # remove literal \"\\\\n\" sequences that came escaped\n",
    "        llm_output = llm_output.replace(\"\\\\n\", \"\")\n",
    "        try:\n",
    "            llm_output = json.loads(llm_output)\n",
    "            print(f\"[PREPROCESS] Successfully parsed LLM output as JSON\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"[ERROR] Failed to parse LLM output as JSON: {e}\")\n",
    "            print(f\"[ERROR] Raw output: {llm_output[:500]}...\")\n",
    "            raise RuntimeError(\"Failed to parse LLM output as JSON:\\n\" + llm_output)\n",
    "\n",
    "    document_class = llm_output.get(\"CLASS\", \"\")\n",
    "    clause_classes = llm_output.get(\"CLAUSES\", [])\n",
    "    \n",
    "    print(f\"[PREPROCESS] Document class: {document_class}\")\n",
    "    print(f\"[PREPROCESS] Extracted {len(clause_classes)} clauses\")\n",
    "\n",
    "\n",
    "    # Step 5: Jurisdiction Estimation\n",
    "    jurisdiction = _estimate_jurisdiction(text, llm_client)\n",
    "    print(\"[PREPROCESS] Step 5: Estimated jurisdiction as:\", jurisdiction)\n",
    "\n",
    "    # Step 6: Storing in Context Bank\n",
    "    print(\"[PREPROCESS] Step 6: Storing in Context Bank...\")\n",
    "    context_bank.add_document(text, {\n",
    "        \"title\": title,\n",
    "        \"document_type\": document_class,\n",
    "        \"source_file\": file_path\n",
    "    })\n",
    "    context_bank.add_entities(entities)\n",
    "    context_bank.add_clauses(clause_classes)\n",
    "    context_bank.add_jurisdiction(jurisdiction)\n",
    "    print(\"[PREPROCESS] Data successfully stored in Context Bank\")\n",
    "    \n",
    "    # print(\"\\n\" + \"=\"*80)\n",
    "    # print(f\"[PREPROCESS] Context Bank state after processing: {json.dumps(context_bank.get_clauses(), indent=2)}\")\n",
    "    # print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    # Final structured output\n",
    "    return {\n",
    "        \"Document Title\": title,\n",
    "        \"Document Class\": document_class,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def preprocess_document_tool(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Creates a tool function for preprocessing legal documents.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the legal document PDF file.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted information.\n",
    "    \"\"\"\n",
    "\n",
    "    SYSTEM_PROMPT = \"\"\"\n",
    "        You are a Pre-processor Agent, a specialized component in the Legal Document Analysis Framework responsible for extracting critical information from legal documents and storing it in the Context Bank. Your work forms the foundation for all subsequent analysis by other agents in the system.\n",
    "\n",
    "        Core Responsibilities:\n",
    "        Your sole task is to extract and structure information from legal documents, including:\n",
    "        - Classifying the document type and purpose\n",
    "        - Extracting important clauses with their classifications\n",
    "        - Storing all extracted information in a structured format accessible to other agents\n",
    "        - Provide your output as strict JSON\n",
    "        Input:\n",
    "        Legal Contract Document PDF.\n",
    "\n",
    "        Output Format:\n",
    "        {\n",
    "        \"CLASS\": \"Document type classification (e.g., Legal Agreement - Employment Contract)\",\n",
    "        \"CLAUSES\": [\n",
    "            {\"Text\": \"Section 3.1: The term of this agreement shall be...\", \"Category\": \"Term Clause\"},\n",
    "            {\"Text\": \"Section 7.2: All disputes shall be resolved by...\", \"Category\": \"Dispute Resolution\"},\n",
    "            {\"Text\": \"Section 9.5: This agreement shall be governed by...\", \"Category\": \"Governing Law\"}\n",
    "        ]\n",
    "        }\n",
    "\n",
    "        [EXTREMELY CRITICAL] Ensure that the output is strictly in JSON format. Do not include any additional text or explanations. The output must be parsable as JSON.\n",
    "    \"\"\"\n",
    "        \n",
    "        # Call the implementation with the shared context bank\n",
    "    return preprocess_document_tool_implementation(file_path, SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processor_agent_tools = [\n",
    "    create_handoff_tool(agent_name=\"Planner Agent\", description=\"Transfer when pre-processing is completed, it helps to plan the next steps in the workflow and delegate tasks.\"),\n",
    "    preprocess_document_tool\n",
    "]\n",
    "\n",
    "pre_processor_agent_node = create_react_agent(\n",
    "    model,\n",
    "    pre_processor_agent_tools,\n",
    "    prompt=\"\"\"\n",
    "         You are the Pre-processor Agent in a Legal Document Analysis Framework. Your sole function is to extract critical information from legal document PDFs and structure it for other agents.\n",
    "\n",
    "         Core Task:\n",
    "         Using the provided tool, preprocess_document_tool, process an input legal document PDF to:\n",
    "         1.   Extract Full Text:  Get the complete text content.\n",
    "         2.   Classify Document:  Determine the document type (e.g., NDA, Lease, Employment Agreement).\n",
    "         3.   Identify Named Entities (NER):  Extract key entities (Parties, Laws, Dates, Jurisdictions, Monetary Values, etc.).\n",
    "         4.   Extract Key Clauses:  Isolate and classify significant clauses (e.g., Term, Governing Law, Confidentiality).\n",
    "         5.   Store Data:  Structure all extracted information (Text, Class, NER list, Clauses list) as a JSON object in the Context Bank.\n",
    "\n",
    "         Input:  Legal Contract Document PDF.\n",
    "         Output:  JSON object with \"TEXT\", \"CLASS\", \"NER\", and \"CLAUSES\" as keys.\n",
    "\n",
    "         Guidelines: \n",
    "         * Be accurate and comprehensive.\n",
    "         * Preserve original context, especially for clauses.\n",
    "         * Focus on legally significant information and obligations.\n",
    "         * Note any low-confidence classifications.\n",
    "         * [CRITICAL STEP] Return to the Planner Agent to update that the pre-processing is completed.\n",
    "      \"\"\",\n",
    "    name=\"Pre Processor Agent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SETUP] Generated test embedding with dimension: 768\n",
      "[SETUP] Creating Qdrant collection with vector size: 768\n",
      "[SETUP] Collection 'web_content' already exists; skipping creation.\n",
      "[SETUP] Successfully created Qdrant collection 'web_content'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import uuid\n",
    "import traceback\n",
    "from typing import List, Dict\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from cleantext import clean\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, PointStruct, Distance\n",
    "# from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Initialize global components once\n",
    "_qdrant_url = \"http://localhost:6333\"\n",
    "_qdrant_collection = \"web_content\"\n",
    "_qdrant_client = QdrantClient(\n",
    "    url=_qdrant_url, \n",
    "    prefer_grpc=False\n",
    ")\n",
    "\n",
    "_num_results = 10\n",
    "_ddgs = DDGS()\n",
    "\n",
    "# Use the GoogleGenerativeAIEmbeddings model instead of OllamaEmbeddings\n",
    "_embeddings_model = embeddings\n",
    "\n",
    "# Optional: create collection if it doesn't exist\n",
    "# Get the embedding dimension from the model by embedding a test string\n",
    "test_embedding = _embeddings_model.embed_query(\"test\")\n",
    "vector_size = len(test_embedding)\n",
    "print(f\"[SETUP] Generated test embedding with dimension: {vector_size}\")\n",
    "\n",
    "try:\n",
    "    print(f\"[SETUP] Creating Qdrant collection with vector size: {vector_size}\")\n",
    "    if not _qdrant_client.collection_exists(_qdrant_collection):\n",
    "        _qdrant_client.create_collection(\n",
    "            collection_name=_qdrant_collection,\n",
    "            vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE),\n",
    "        )\n",
    "    else:\n",
    "        print(f\"[SETUP] Collection '{_qdrant_collection}' already exists; skipping creation.\")\n",
    "\n",
    "    print(f\"[SETUP] Successfully created Qdrant collection '{_qdrant_collection}'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to create Qdrant collection. Encountered an exception.\")\n",
    "    print(f\"[ERROR] {type(e).__name__}: {e}\")\n",
    "    traceback.print_exc()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def retrieve_web_knowledge_tool(query: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Searches the web for a legal/policy topic,\n",
    "    scrapes and cleans page content, generates embeddings with Google Gen AI,\n",
    "    stores them in Qdrant, and retrieves top relevant results.\n",
    "    Returns a list of summarized search results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Tavily search\n",
    "    print(f\"[KNOWLEDGE] Searching Tavily for query: {query}\")\n",
    "    # results = list(_ddgs.text(query, max_results=10))\n",
    "\n",
    "    tavily_client = TavilyClient(tavily_api_key)\n",
    "    results = tavily_client.search(query, max_results=10)\n",
    "\n",
    "    # print(f\"[INFO] Tavily results: {results}\")\n",
    "\n",
    "    url_results = results.get(\"results\", [])\n",
    "    \n",
    "    print(f\"[KNOWLEDGE] Found {len(url_results)} results from Tavily search\")\n",
    "\n",
    "\n",
    "    # Step 2: Scrape + clean + embed + store\n",
    "    points_to_upsert = []\n",
    "    successful_urls = 0\n",
    "    for i, result in enumerate(url_results):\n",
    "        try:\n",
    "            url = result[\"url\"]\n",
    "            title = result[\"title\"]\n",
    "            print(f\"[KNOWLEDGE] Processing result {i+1}/{len(url_results)}: {title}\")\n",
    "\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status() # Raise an exception for bad status codes\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            paragraphs = soup.find_all(\"p\")\n",
    "            content = \" \".join(p.get_text() for p in paragraphs)\n",
    "            content = \" \".join(content.split()) # Remove extra whitespace\n",
    "            cleaned_content = clean(\n",
    "                content,\n",
    "                fix_unicode=True,\n",
    "                to_ascii=True,\n",
    "                lower=True,\n",
    "                no_line_breaks=True,\n",
    "                lang=\"en\"\n",
    "            )\n",
    "\n",
    "            if not cleaned_content: # Skip if content is empty after cleaning\n",
    "                print(f\"[KNOWLEDGE] No content found or extracted for URL {url}\")\n",
    "                continue\n",
    "\n",
    "            # Generate embeddings using Google Gen AI embeddings model\n",
    "            generated_embeddings = _embeddings_model.embed_query(text=cleaned_content)\n",
    "            point_id = str(uuid.uuid5(uuid.NAMESPACE_URL, url))\n",
    "\n",
    "            points_to_upsert.append(\n",
    "                PointStruct( # Use PointStruct for clarity\n",
    "                    id=point_id,\n",
    "                    vector=generated_embeddings,\n",
    "                    payload={\n",
    "                        \"title\": title,\n",
    "                        \"content\": cleaned_content,\n",
    "                        \"url\": url\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "            successful_urls += 1\n",
    "            print(f\"[KNOWLEDGE] Successfully processed URL: {url}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"[ERROR] Failed to fetch URL {url}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process URL {url}: {e}\") # Catch other potential errors\n",
    "\n",
    "    # Upsert points in batch if any were successfully processed\n",
    "    if points_to_upsert:\n",
    "        print(f\"[KNOWLEDGE] Upserting {len(points_to_upsert)} documents to Qdrant collection\")\n",
    "        try:\n",
    "            _qdrant_client.upsert(\n",
    "                collection_name=_qdrant_collection,\n",
    "                points=points_to_upsert,\n",
    "                wait=True # Optional: wait for operation to complete\n",
    "            )\n",
    "            print(f\"[KNOWLEDGE] Successfully upserted {len(points_to_upsert)} documents to Qdrant\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to upsert to Qdrant: {e}\")\n",
    "    else:\n",
    "        print(f\"[KNOWLEDGE] No documents to upsert to Qdrant\")\n",
    "        \n",
    "    print(f\"[KNOWLEDGE] Retrieved and processed {successful_urls} out of {len(url_results)} URLs\")\n",
    "    return [{\"status\": \"knowledge search completed\", \"total_urls\": len(url_results)}]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knowledge_agent_tools = [\n",
    "    create_handoff_tool(agent_name=\"Planner Agent\", description=\"Transfer to Planner Agent when knowledge has been retrieved and pass a summary back to it.\"),\n",
    "    retrieve_web_knowledge_tool\n",
    "]\n",
    "\n",
    "knowledge_agent_node = create_react_agent(\n",
    "    model,\n",
    "    knowledge_agent_tools,\n",
    "    prompt=\"\"\"\n",
    "        You are a Knowledge Retrieval Agent tasked with extracting accurate, up-to-date legal information from official U.S. government sources. You use the retrieve_web_knowledge_tool to search for legal/policy topics, scrape and clean page content, generate embeddings, store them in Qdrant, and retrieve top relevant results. \n",
    "        Your work is crucial for ensuring that the Compliance Checker Agent has access to the most current and relevant legal information.\n",
    "\n",
    "        Use the retrieve_web_knowledge_tool to fetch up-to-date legal data from trusted government sites and perform the following functions:\n",
    "        * Retrieve relevant statutes, regulations, and policies based on a given topic.\n",
    "        * Ensure content is current, authoritative, and clearly summarized.\n",
    "        * Avoid non-official, outdated, or speculative sources.\n",
    "        * Store the retrieved knowledge in a vector database for later use by the Compliance Checker Agent.\n",
    "\n",
    "        Search Query Format:\n",
    "        site:[gov source] \"[TOPIC]\" AND \"[FOCUS]\" AND (\"[KEYWORD1]\" OR \"[KEYWORD2]\") after:[YEAR]\n",
    "\n",
    "        Sources: congress.gov, govinfo.gov, law.cornell.edu, federalregister.gov, ecfr.gov, justice.gov, whitehouse.gov, govinfo.gov\n",
    "\n",
    "        Output Format: Return a simple sentence with the status of the knowledge retrieval.\n",
    "\n",
    "        Guidelines:\n",
    "        * Use only listed government sources.\n",
    "        * Do not fabricate or paraphrase inaccurately.\n",
    "        * If no reliable info is found, say so.\n",
    "        * [CRITICAL STEP] Return to the Planner Agent to update that the knowledge retrieval is completed.\n",
    "    \"\"\",\n",
    "    name=\"Knowledge Agent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from langchain_core.tools import tool\n",
    "from agents.compliance_checker import check_legal_compliance\n",
    "from context_bank import ContextBank\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from agents.utils.websearcher import WebContentRetriever\n",
    "\n",
    "\n",
    "# TODO : Add a function TOOL to check the relevance of knowledge fetched from the vector database\n",
    "@tool\n",
    "def check_knowledge_relevance_tool() -> List[str]:\n",
    "    \"\"\"\n",
    "    Tool to check the relevance of knowledge fetched from the vector database.\n",
    "    This tool will return a list of topics missing from the vector database. This list will be used by the knowledge agent to fetch the missing knowledge.\n",
    "    \n",
    "    Returns:\n",
    "        List of relevant topics that are needed for complaiance checking but are not present in the vector database.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # fetch all the information from the context bank\n",
    "    context_data = context_bank.get_all()\n",
    "\n",
    "    highlights_system_prompt = \"\"\"\n",
    "        Use the input context data to figure out all the important topics of the legal document. These topics will be necessary to perform a compliance check on the legal document.\n",
    "        These highlights will be needed for compliance checking and will be used to check the relevance of the knowledge fetched from the vector database.\n",
    "        OUTPUT: Only return a comma separated list of important topics from the input context data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the context data to a string format that can be used by the LLM\n",
    "    context_data_str = json.dumps(context_data, indent=2)\n",
    "\n",
    "    highlights_prompt = f\"\"\"{highlights_system_prompt} : context_data = {context_data_str}\"\"\"\n",
    "\n",
    "    highlights = llm_client.query(highlights_prompt)\n",
    "    print(f\"[KNOWLEDGE] Highlights: {highlights}\")\n",
    "\n",
    "    # TODO : Implement this logic to use the context data highlights along with the knowledge from the vector database to check relevance\n",
    "\n",
    "    relevance_system_prompt = \"\"\"\n",
    "        Using the input highlights of the legal document and the knowledge fetched from the vector database, check if the knowledge is relevant to the compliance checking of the legal document.\n",
    "        If the knowledge is relevant, return an empty list. If the knowledge is not relevant, return a list of topics that are missing from the knowledge fetched from the vector database.\n",
    "        The missing topics would be important for compliance checkeing and will be used to fetch missing knowledge from the web using the knowledge agent's websearcher tool.\n",
    "        OUTPUT: Only return a comma separated python list of topics missing from the knowledge fetched from the vector database when compared with the highlights of the legal document.\n",
    "    \"\"\"\n",
    "\n",
    "    query = \"Retrieve all relevant legal knowledge for compliance checking.\"\n",
    "\n",
    "    jurisdiction = context_bank.get_jurisdiction()\n",
    "  \n",
    "    doc_meta_from_bank = context_bank.get_document()\n",
    "    # Extract the document_type from the retrieved metadata\n",
    "    # Provide a default value if the key is missing\n",
    "    document_type = doc_meta_from_bank.get(\"document_type\", \"Unknown Document Type\") \n",
    "\n",
    "    knowledge_data = get_knowledge_from_vector_db(query, jurisdiction, document_type)\n",
    "\n",
    "\n",
    "    missing_topics = []\n",
    "\n",
    "    relevance_prompt = f\"\"\"{relevance_system_prompt}  legal document highlights : {highlights} and knowledge collected so far, fetched from the vector DB : {knowledge_data}\"\"\"\n",
    "\n",
    "    print(f\"[KNOWLEDGE] Performing relevance check\")\n",
    "\n",
    "    missing_topics = llm_client.query(relevance_prompt)\n",
    "\n",
    "    print(f\"[KNOWLEDGE] Missing Topics: {missing_topics}\")\n",
    "\n",
    "    return missing_topics\n",
    "\n",
    "\n",
    "# Create an instance of WebContentRetriever to use for querying the vector database\n",
    "def get_knowledge_from_vector_db(query, jurisdiction, document_type: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Retrieves legal knowledge from the vector database based on the query,\n",
    "    jurisdiction, and knowledge type.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query string\n",
    "        jurisdiction: The legal jurisdiction (default: \"US\")\n",
    "        \n",
    "    Returns:\n",
    "        List of relevant knowledge items with title, content, URL, and relevance score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Refine the query with jurisdiction and knowledge type for better results\n",
    "    refined_query = f\"{query} jurisdiction:{jurisdiction} document_type:{document_type}\"\n",
    "    print(f\"[KNOWLEDGE RETRIEVAL] Refined query: {refined_query}\")\n",
    "\n",
    "    try:\n",
    "        print(\"[KNOWLEDGE RETRIEVAL] Querying vector database...\")\n",
    "        query_vec = _embeddings_model.embed_query(text=refined_query)\n",
    "        search_results = _qdrant_client.search(\n",
    "            collection_name=_qdrant_collection,\n",
    "            query_vector=query_vec,\n",
    "            with_payload=True,\n",
    "            limit=_num_results\n",
    "        ) # search returns Hit objects directly\n",
    "\n",
    "        print(f\"[KNOWLEDGE RETRIEVAL] Retrieved {len(search_results)} search results\")\n",
    "\n",
    "        results = [\n",
    "            {\n",
    "                \"title\": result.payload[\"title\"],\n",
    "                \"content\": result.payload[\"content\"][:400] + \"...\",\n",
    "                \"url\": result.payload[\"url\"],\n",
    "                \"relevance\": result.score\n",
    "            }\n",
    "            for result in search_results\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to retrieve knowledge from vector DB: {e}\")\n",
    "        return [] # Return empty list on search failure\n",
    "    \n",
    "    print(f\"[KNOWLEDGE RETRIEVAL] Completed with {len(results)} knowledge items\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Create a tool that the ComplianceCheckerAgent can use\n",
    "\n",
    "@tool\n",
    "def compliance_check_tool() -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Tool for checking legal document clauses for compliance issues.\n",
    "    Performs the following tasks:\n",
    "    Fetches all legal clauses from the context bank\n",
    "    Retrieves relevant legal laws and regulations from the vector database\n",
    "    Performs compliance checks on the clauses using the gathered knowledge\n",
    "    Detects compliance issues: statutory, precedent-based, internal.\n",
    "    Ensures internal consistency across clauses\n",
    "    Identifies legal risks and their implications\n",
    "    Provides structured legal reasoning and confidence scores\n",
    "    \n",
    "        \n",
    "    Returns:\n",
    "        List of non-compliant clauses with detailed analysis\n",
    "    \"\"\"\n",
    "\n",
    "    # Adding a delay here to avoid hitting API rate limits\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Get clauses from context bank\n",
    "    clauses = context_bank.get_clauses()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"[COMPLIANCE CHECKER] Starting compliance check for {len(clauses)} clauses\")\n",
    "    # print(f\"[COMPLIANCE CHECKER] Context Bank state at start: {json.dumps(context_bank.get_all(), indent=2)}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    print(f\"The list of clauses is: {clauses}\")\n",
    "\n",
    "\n",
    "    query = \"Retrieve all relevant legal knowledge for compliance checking.\"\n",
    "\n",
    "    jurisdiction = context_bank.get_jurisdiction()\n",
    "  \n",
    "    doc_meta_from_bank = context_bank.get_document()\n",
    "    # Extract the document_type from the retrieved metadata\n",
    "    # Provide a default value if the key is missing\n",
    "    document_type = doc_meta_from_bank.get(\"document_type\", \"Unknown Document Type\") \n",
    "    \n",
    "    print(f\"[COMPLIANCE CHECKER] Using jurisdiction: {jurisdiction}\")\n",
    "    print(f\"[COMPLIANCE CHECKER] Using document type: {document_type}\")\n",
    "\n",
    "    # Create a knowledge retrieval adapter that mimics a knowledge agent\n",
    "    # but actually uses the vector DB directly\n",
    "    print(\"[COMPLIANCE CHECKER] Retrieving knowledge from vector DB...\")\n",
    "    knowledge_data = get_knowledge_from_vector_db(query, jurisdiction, document_type)\n",
    "    print(f\"[COMPLIANCE CHECKER] Retrieved {len(knowledge_data)} knowledge items\")\n",
    "    \n",
    "    print(\"[COMPLIANCE CHECKER] Checking legal compliance...\")\n",
    "    results = check_legal_compliance(\n",
    "        context_bank=context_bank,\n",
    "        knowledge_from_vector_db=knowledge_data,\n",
    "        use_ollama=False,\n",
    "        # model_name=\"llama3.1:latest\",\n",
    "        model_name=\"gemini-2.0-flash\",\n",
    "        min_confidence=0.75\n",
    "    )\n",
    "    \n",
    "    print(f\"[COMPLIANCE CHECKER] Compliance check completed with {len(results)} results\")\n",
    "    # print(\"\\n\" + \"=\"*80)\n",
    "    # print(f\"[COMPLIANCE CHECKER] Context Bank state after check: {json.dumps(context_bank.get_all(), indent=2)}\")\n",
    "    # print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Add analysis of the compliance check results to the context bank\n",
    "\n",
    "\n",
    "compliance_checker_agent_tools = [\n",
    "    create_handoff_tool(agent_name=\"Knowledge Agent\", description=\"Transfer to Knowledge Agent if more knowledge is needed, it helps to retrieve knowledge from the web using websearcher.\"),\n",
    "    create_handoff_tool(agent_name=\"Planner Agent\", description=\"Transfer to Planner Agent when compliance checking is completed and all clauses are found to be compliant, it helps to plan the next steps in the workflow and delegate tasks.\"),\n",
    "    compliance_check_tool,\n",
    "    check_knowledge_relevance_tool\n",
    "]\n",
    "\n",
    "compliance_checker_agent_node = create_react_agent(\n",
    "    model,\n",
    "    compliance_checker_agent_tools,\n",
    "    prompt=\"\"\"\n",
    "      You are the Compliance Checker Agent, responsible for analyzing a list of extracted legal clauses to identify contradictions, ensure statutory compliance, and assess contractual consistency under U.S. law.\n",
    "\n",
    "      You will use the check_knowledge_relevance_tool to check the relevance of the knowledge fetched from the vector database and to identify any missing topics that are needed for compliance checking.\n",
    "      If the tool returns a list of missing topics, you will pass the list of missing topics to the Knowledge Agent to fetch the missing knowledge from the web using the websearcher tool. Do not perform this step more than once.\n",
    "      If the tool returns an empty list, you will proceed with the compliance check using the compliance_check_tool.\n",
    "\n",
    "      The check_knowledge_relevance_tool:\n",
    "      * Fetches all the data from the context bank\n",
    "      * Finds the highlights of the legal document from that data\n",
    "      * Checks the relevance of the knowledge fetched from the vector database against the highlights of the legal document\n",
    "      * Returns a list of missing topics, knowledge for which needs to be fetched from the web using the Knowledge Agent\n",
    "\n",
    "      [CRITICAL] After this is done, use the compliance_check_tool.\n",
    "      You will use the compliance_check_tool to fetch all the **legal clauses from the context bank** and **relevant laws and regulations retrieved from the vector database** to perform a compliance check for the clauses against the legal knowledge.\n",
    "      Your task is to ensure that the clauses are compliant with federal, state, and city laws, and to identify any legal risks or implications associated with non-compliance.\n",
    "      Your work is crucial for ensuring that the legal document is compliant with all relevant laws and regulations.\n",
    "\n",
    "      Use the compliance_check_tool to perform the following primary functions:\n",
    "      * Fetch all legal clauses from the context bank\n",
    "      * Retrieve relevant legal laws and regulations from the vector database\n",
    "      * Perform compliance checks on the clauses using the gathered knowledge\n",
    "      * Detect compliance issues: statutory, precedent-based, internal.\n",
    "      * Ensure internal consistency across clauses\n",
    "      * Identify legal risks and their implications\n",
    "      * Provide structured legal reasoning and confidence scores\n",
    "\n",
    "      Output:\n",
    "      1. Contradiction Report\n",
    "      {\n",
    "        \"has_contradiction\": true|false,\n",
    "        \"contradiction_type\": \"statutory|precedent|internal\",\n",
    "        \"severity\": \"high|medium|low\",\n",
    "        \"description\": \"...\",\n",
    "        \"source_clause\": { \"id\": \"...\", \"text\": \"...\" },\n",
    "        \"reference\": { \"type\": \"...\", \"id\": \"...\", \"text\": \"...\" }\n",
    "      }\n",
    "      2. Reasoning & Analysis\n",
    "      {\n",
    "        \"analysis_steps\": [\"Step 1...\", \"Step 2...\", \"Step 3...\"],\n",
    "        \"confidence_score\": 0.0–1.0,\n",
    "        \"supporting_references\": [{ \"type\": \"statute\", \"id\": \"...\", \"relevance\": \"...\" }]\n",
    "      }\n",
    "      3. Legal Implications\n",
    "      {\n",
    "        \"implications\": [\n",
    "          {\n",
    "            \"description\": \"...\",\n",
    "            \"severity\": \"high|medium|low\",\n",
    "            \"affected_parties\": [\"...\"],\n",
    "            \"risk_areas\": [\"...\"]\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "\n",
    "\n",
    "      [CRITICAL STEP] Decision Flow:\n",
    "      If there are topics missing according to the check_knowledge_relevance_tool, call the Knowledge Agent with the missing topics to retrieve information on them.\n",
    "      If compliance check is complete, return to the Planner Agent for post processing where the whole process is summarized by the Post Processor Agent.\n",
    "\n",
    "      Guidelines:\n",
    "      * Use only validated legal sources\n",
    "      * No fabrication or assumptions\n",
    "      * Flag unclear issues and recommend human review when needed\n",
    "      * Consider jurisdictional scope and maintain objectivity\n",
    "      * [CRITICAL STEP] Return to the Planner Agent to update that the compliance check is completed.\n",
    "    \"\"\",\n",
    "    name=\"Compliance Checker Agent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO : Add the other tools for Clause Rewriter Agent -\n",
    "\n",
    "# clause_rewriter_agent_tools = [\n",
    "#     create_handoff_tool(agent_name=\"Compliance Checker Agent\", description=\"Transfer to Compliance Checker Agent after a non-compliant clause has been rewritten, it helps to check the compliance of the rewritten clause.\"),\n",
    "# ]\n",
    "\n",
    "# clause_rewriter_agent_node = create_react_agent(\n",
    "#     model,\n",
    "#     clause_rewriter_agent_tools,\n",
    "#     prompt=\"\"\"\n",
    "#     You are the Clause Rewriter Agent, tasked with revising legal clauses flagged as non-compliant, contradictory, or unclear by the Compliance Checker Agent. Your goal is to ensure legal compliance while preserving the original intent.\n",
    "\n",
    "# Responsibilities:\n",
    "# Rewrite clauses to resolve statutory, precedent-based, or internal contradictions\n",
    "# Ensure clarity, enforceability, and alignment with U.S. law\n",
    "# Maintain intent and context of original clause\n",
    "# Signal if more legal context is required (route to Knowledge Agent)\n",
    "\n",
    "# Input Format:\n",
    "# {\n",
    "#   \"original_clause\": {\n",
    "#     \"id\": \"clause_id\",\n",
    "#     \"text\": \"original text\"\n",
    "#   },\n",
    "#   \"issue\": {\n",
    "#     \"description\": \"reason for non-compliance\",\n",
    "#     \"contradiction_type\": \"statutory|precedent|internal\",\n",
    "#     \"reference\": {\n",
    "#       \"type\": \"statute|precedent|clause\",\n",
    "#       \"text\": \"reference text\",\n",
    "#       \"source_link\": \"optional\"\n",
    "#     }\n",
    "#   },\n",
    "#   \"context_info\": {\n",
    "#     \"document_title\": \"Title\",\n",
    "#     \"named_entities\": [...],\n",
    "#     \"document_class\": \"e.g., NDA, Lease\"\n",
    "#   }\n",
    "# }\n",
    "# Output Format:\n",
    "# {\n",
    "#   \"clause_id\": \"clause_id\",\n",
    "#   \"rewritten_clause\": \"Compliant version of the clause\",\n",
    "#   \"justification\": \"How it resolves the issue and aligns with legal standards\"\n",
    "# }\n",
    "# Guidelines:\n",
    "# Be concise, precise, and legally sound\n",
    "# Do not fabricate or generalize\n",
    "# Flag insufficient context when needed\n",
    "\n",
    "#     \"\"\",\n",
    "#     name=\"Clause Rewriter Agent\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Add the other tools for Post-Processor Agent - Process Summarizer, Context Bank getter\n",
    "\n",
    "post_processor_agent_tools = [\n",
    "    create_handoff_tool(agent_name=\"Planner Agent\", description=\"Transfer to Planner Agent when post-processing is completed, it helps to plan the next steps in the workflow and delegate tasks.\"),\n",
    "]\n",
    "\n",
    "post_processor_agent_node = create_react_agent(\n",
    "    model,\n",
    "    post_processor_agent_tools,\n",
    "    prompt=\"\"\"\n",
    "        You are the Post-processor Agent, responsible for generating final, human-readable outputs after a legal document passes all compliance checks.\n",
    "\n",
    "        Input:\n",
    "        Context Bank (document metadata, clause info)\n",
    "        Compliance Checker outputs (reasoning, implications)\n",
    "        History of tasks done\n",
    "        Tools: Summarizer\n",
    "        Outputs (via Process Summarizer):\n",
    "        Contract Summary – Overview of the document\n",
    "        Changes – Highlighted clause modifications\n",
    "        Risks Averted – Legal issues resolved\n",
    "        References – Cited statutes and precedents\n",
    "\n",
    "        Guidelines:\n",
    "        * Be clear, concise, and legally accurate\n",
    "        * Avoid jargon or speculation\n",
    "        * Tailor for legal and business audiences\n",
    "        * [CRITICAL STEP] Return the summary to the Planner Agent and update that the post processing is completed.\n",
    "\"\"\",\n",
    "    name=\"Post Processor Agent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[WORKFLOW] Multi-agent swarm initialized with the following agents:\n",
      "  - Planner Agent\n",
      "  - Pre Processor Agent\n",
      "  - Knowledge Agent\n",
      "  - Compliance Checker Agent\n",
      "  - Post Processor Agent\n",
      "[WORKFLOW] Default active agent: Planner Agent\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "workflow = create_swarm(\n",
    "    [planner_agent_node, pre_processor_agent_node, knowledge_agent_node, compliance_checker_agent_node, post_processor_agent_node],\n",
    "    default_active_agent=\"Planner Agent\"\n",
    ")\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[WORKFLOW] Multi-agent swarm initialized with the following agents:\")\n",
    "print(\"  - Planner Agent\")\n",
    "print(\"  - Pre Processor Agent\")\n",
    "print(\"  - Knowledge Agent\")\n",
    "print(\"  - Compliance Checker Agent\")\n",
    "print(\"  - Post Processor Agent\")\n",
    "print(\"[WORKFLOW] Default active agent: Planner Agent\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[PREPROCESS] Starting document preprocessing for: ./Original and Modified/modified_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf\n",
      "================================================================================\n",
      "\n",
      "[PREPROCESS] Step 1: Extracting text from PDF...\n",
      "[PREPROCESS] Extracted 167916 characters of text\n",
      "[PREPROCESS] Step 2: Extracting title...\n",
      "[PREPROCESS] Extracted title: Based on the provided text, the title of the document is:\n",
      "\n",
      "**NETWORK 1 FINANCIAL CORPORATION AFFILIATE OFFICE AGREEMENT**\n",
      "[PREPROCESS] Step 3: Performing Named Entity Recognition...\n",
      "[PREPROCESS] Extracted 3165 named entities\n",
      "[PREPROCESS] Sample entities (first 5): [('10.11', 'CARDINAL'), ('NETWORK 1 FINANCIAL CORPORATION', 'WORK_OF_ART'), ('AGREEMENT', 'GPE'), ('NETWORK 1 FINANCIAL, INC.', 'ORG'), ('NETWORK 1', 'WORK_OF_ART')]\n",
      "[PREPROCESS] Step 4: Classifying document and clauses...\n",
      "[PREPROCESS] Successfully parsed LLM output as JSON\n",
      "[PREPROCESS] Document class: Legal Agreement - Affiliate Office Agreement\n",
      "[PREPROCESS] Extracted 5 clauses\n",
      "[PREPROCESS] Step 5: Estimated jurisdiction as: Virginia\n",
      "[PREPROCESS] Step 6: Storing in Context Bank...\n",
      "[PREPROCESS] Data successfully stored in Context Bank\n",
      "[KNOWLEDGE] Searching Tavily for query: site:govinfo.gov \"Affiliate Office Agreement\" AND \"Compliance\" AND (\"Regulations\" OR \"Statutes\") after:2020\n",
      "[KNOWLEDGE] Found 10 results from Tavily search\n",
      "[KNOWLEDGE] Processing result 1/10: Rules and Regulations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNOWLEDGE] No content found or extracted for URL https://www.govinfo.gov/content/pkg/FR-2021-02-12/pdf/2021-01499.pdf\n",
      "[KNOWLEDGE] Processing result 2/10: Rules and Regulations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNOWLEDGE] No content found or extracted for URL https://www.govinfo.gov/content/pkg/FR-2022-01-28/pdf/2022-01607.pdf\n",
      "[KNOWLEDGE] Processing result 3/10: Rules and Regulations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNOWLEDGE] No content found or extracted for URL https://www.govinfo.gov/content/pkg/FR-2021-02-23/pdf/2020-28473.pdf\n",
      "[KNOWLEDGE] Processing result 4/10: Federal Register/Vol. 89, No. 89/Tuesday, May 7, 2024/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNOWLEDGE] No content found or extracted for URL https://www.govinfo.gov/link/fr/89/38293\n",
      "[KNOWLEDGE] Processing result 5/10: Public Law 95-369 95th Congress An Act\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNOWLEDGE] Successfully processed URL: https://www.govinfo.gov/content/pkg/STATUTE-92/pdf/STATUTE-92-Pg607.pdf\n",
      "[KNOWLEDGE] Processing result 6/10: Public Law 95-521 95th Congress An Act\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNOWLEDGE] No content found or extracted for URL https://www.govinfo.gov/content/pkg/STATUTE-92/pdf/STATUTE-92-Pg1824.pdf\n",
      "[KNOWLEDGE] Processing result 7/10: Federal Register/Vol. 90, No. 9/Wednesday, January 15, 2025 ...\n",
      "[KNOWLEDGE] No content found or extracted for URL https://www.govinfo.gov/content/pkg/FR-2025-01-15/pdf/2025-00636.pdf\n",
      "[KNOWLEDGE] Processing result 8/10: Federal Register/Vol. 90, No. 5/Wednesday, January 8, ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNOWLEDGE] No content found or extracted for URL https://www.govinfo.gov/content/pkg/FR-2025-01-08/pdf/2024-31486.pdf\n",
      "[KNOWLEDGE] Processing result 9/10: Rules and Regulations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNOWLEDGE] No content found or extracted for URL https://www.govinfo.gov/content/pkg/FR-2021-02-11/pdf/2020-28943.pdf\n",
      "[KNOWLEDGE] Processing result 10/10: Federal Register/Vol. 89, No. 12/Thursday, January 18, ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNOWLEDGE] No content found or extracted for URL https://www.govinfo.gov/content/pkg/FR-2024-01-18/pdf/2023-28629.pdf\n",
      "[KNOWLEDGE] Upserting 1 documents to Qdrant collection\n",
      "[KNOWLEDGE] Successfully upserted 1 documents to Qdrant\n",
      "[KNOWLEDGE] Retrieved and processed 1 out of 10 URLs\n",
      "[KNOWLEDGE] Highlights: Affiliate Office Agreement, Contractor Obligations, Merchant Agreements, Payment Processing Services, ISO Sponsorship, Termination Conditions, Indemnification, Restrictions on Affiliate, Compensation, Independent Contractor Status, Dispute Resolution, Use of Network 1 Name, Equipment Purchase and Lease, Term and Renewal, Assignment, Governing Law.\n",
      "[KNOWLEDGE RETRIEVAL] Refined query: Retrieve all relevant legal knowledge for compliance checking. jurisdiction:Virginia document_type:Unknown Document Type\n",
      "[KNOWLEDGE RETRIEVAL] Querying vector database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/67/79fgxv_911q4lk20g_fbhp7h0000gn/T/ipykernel_85450/71641224.py:95: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = _qdrant_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNOWLEDGE RETRIEVAL] Retrieved 10 search results\n",
      "[KNOWLEDGE RETRIEVAL] Completed with 10 knowledge items\n",
      "[KNOWLEDGE] Performing relevance check\n",
      "[KNOWLEDGE] Missing Topics: Affiliate Office Agreement, Contractor Obligations, Merchant Agreements, Payment Processing Services, ISO Sponsorship, Termination Conditions, Indemnification, Restrictions on Affiliate, Compensation, Independent Contractor Status, Dispute Resolution, Use of Network 1 Name, Equipment Purchase and Lease, Term and Renewal, Assignment, Governing Law\n",
      "[KNOWLEDGE] Searching Tavily for query: site:ecfr.gov \"Independent Contractor Status\" AND \"Regulations\" AND (\"IRS guidelines\" OR \"Labor laws\") after:2020\n",
      "[KNOWLEDGE] Found 0 results from Tavily search\n",
      "[KNOWLEDGE] No documents to upsert to Qdrant\n",
      "[KNOWLEDGE] Retrieved and processed 0 out of 0 URLs\n",
      "[KNOWLEDGE] Searching Tavily for query: site:irs.gov \"Independent Contractor Status\" AND \"Regulations\" AND (\"IRS guidelines\" OR \"Labor laws\") after:2020\n",
      "[KNOWLEDGE] Found 0 results from Tavily search\n",
      "[KNOWLEDGE] No documents to upsert to Qdrant\n",
      "[KNOWLEDGE] Retrieved and processed 0 out of 0 URLs\n",
      "[KNOWLEDGE] Searching Tavily for query: site:dol.gov \"Independent Contractor Status\" AND \"Regulations\" AND (\"IRS guidelines\" OR \"Labor laws\") after:2020\n",
      "[KNOWLEDGE] Found 2 results from Tavily search\n",
      "[KNOWLEDGE] Processing result 1/2: Misclassification of Employees as Independent Contractors ...\n",
      "[KNOWLEDGE] Successfully processed URL: https://www.dol.gov/agencies/whd/flsa/misclassification\n",
      "[KNOWLEDGE] Processing result 2/2: Fact Sheet 13: Employment Relationship Under the Fair ...\n",
      "[KNOWLEDGE] Successfully processed URL: https://www.dol.gov/agencies/whd/fact-sheets/13-flsa-employment-relationship\n",
      "[KNOWLEDGE] Upserting 2 documents to Qdrant collection\n",
      "[KNOWLEDGE] Successfully upserted 2 documents to Qdrant\n",
      "[KNOWLEDGE] Retrieved and processed 2 out of 2 URLs\n",
      "\n",
      "================================================================================\n",
      "[COMPLIANCE CHECKER] Starting compliance check for 5 clauses\n",
      "================================================================================\n",
      "\n",
      "The list of clauses is: [{'Text': 'This AGREEMENT is entered into by and between NETWORK 1 FINANCIAL, INC. (\"NETWORK 1\"), a Virginia Corporation with its principal place of business at 1501 Farm Credit Drive, Suite 1500, McLean, Virginia 22102-5004, and Payment Data Systems, Inc., the Affiliate Office (\"AFFILIATE\"), a Nevada Corporation with its principal place of business at 12500 San Pedro Suite 120 San Antonio, TX 78216.', 'Category': 'Parties and Definitions'}, {'Text': 'The term (\"Term\") of this Agreement shall be for one hundred eighty days (180) from the date set forth below unless Network 1 or Visa or MasterCard or Harris Bank doesn\\'t approve Affiliate\\'s ISO application, in which case, the Term will be 3 years. This Agreement will automatically renew for successive one-year terms unless terminated by either party by providing the other with 30 days written notice that this Agreement will not be renewed or Affiliate enters into a Processing agreement with Network 1 and an ISO Sponsorship agreement with Harris Bank in which case this Agreement will automatically terminate concurrent with the execution of such agreements.', 'Category': 'Term and Renewal'}, {'Text': \"Affiliate hereby agrees to indemnify and hold harmless Network 1, VISA, MasterCard and the Member Bank from and against any loss, cost or damage (including reasonable legal fees and court costs) incurred by Network 1, VISA, MasterCard and the Member Bank as a result of Affiliate's failure to comply with the terms of this Agreement, Affiliate's misrepresentation with respect to this Agreement or Affiliate's knowing or negligent misrepresentation with respect to Contractors.\", 'Category': 'Indemnification'}, {'Text': 'All disputes or claims hereunder shall be resolved by arbitration in McLean, Virginia, pursuant to the rules of the American Arbitration Association.', 'Category': 'Dispute Resolution'}, {'Text': 'This agreement may be assigned or delegated, in whole or in part, by NETWORK 1 without the prior written consent of the other party herein. This agreement may not be assigned or delegated by Affiliate without prior written consent from Network 1. Such consent shall not be unreasonably withheld.', 'Category': 'Assignment'}]\n",
      "[COMPLIANCE CHECKER] Using jurisdiction: Virginia\n",
      "[COMPLIANCE CHECKER] Using document type: Unknown Document Type\n",
      "[COMPLIANCE CHECKER] Retrieving knowledge from vector DB...\n",
      "[KNOWLEDGE RETRIEVAL] Refined query: Retrieve all relevant legal knowledge for compliance checking. jurisdiction:Virginia document_type:Unknown Document Type\n",
      "[KNOWLEDGE RETRIEVAL] Querying vector database...\n",
      "[KNOWLEDGE RETRIEVAL] Retrieved 10 search results\n",
      "[KNOWLEDGE RETRIEVAL] Completed with 10 knowledge items\n",
      "[COMPLIANCE CHECKER] Retrieved 10 knowledge items\n",
      "[COMPLIANCE CHECKER] Checking legal compliance...\n",
      "Starting legal compliance check with model 'gemini-2.0-flash' (use_ollama=False)\n",
      "Initializing API client with model gemini-2.0-flash\n",
      "Jurisdiction from context bank: Virginia\n",
      "Document type from metadata: Legal Agreement - Affiliate Office Agreement\n",
      "Found 5 clauses and 3165 entities\n",
      "Processing 10 knowledge items from vector database\n",
      "Classified knowledge: 9 statutes, 1 precedents\n",
      "Prepared knowledge context with 9 statutes and 1 precedents\n",
      "Analyzing clause 1/5 (ID: unknown)\n",
      "Clause Text: This AGREEMENT is entered into by and between NETWORK 1 FINANCIAL, INC. (\"NETWORK 1\"), a Virginia Corporation with its principal place of business at 1501 Farm Credit Drive, Suite 1500, McLean, Virginia 22102-5004, and Payment Data Systems, Inc., the Affiliate Office (\"AFFILIATE\"), a Nevada Corporation with its principal place of business at 12500 San Pedro Suite 120 San Antonio, TX 78216.\n",
      "Clause Category: Parties and Definitions\n",
      "Analyzing compliance for clause ID 12ab2c86-5d88-4000-8ac5-c569c709e4c3\n",
      "Checking statutory compliance against 9 statutes\n",
      "Validating statutory compliance for clause 12ab2c86-5d88-4000-8ac5-c569c709e4c3 in Virginia jurisdiction\n",
      "Analyzing against 9 relevant statutes\n",
      "Identified 4 potential statutory issues\n",
      "ERROR: Error in statutory validation: 'str' object has no attribute 'get'\n",
      "Checking precedent compliance against 1 precedents\n",
      "Analyzing precedent compliance for clause 12ab2c86-5d88-4000-8ac5-c569c709e4c3\n",
      "Analyzing against 1 precedents in Virginia jurisdiction\n",
      "Identified 0 potential precedent issues\n",
      "Found 0 valid precedent issues with confidence >= 0.75\n",
      "Found 0 precedent issues\n",
      "Checking consistency against 0 other clauses\n",
      "Starting contractual consistency check for 1 clauses (min_confidence=0.75)\n",
      "WARNING: Not enough clauses for consistency analysis\n",
      "Found 0 consistency issues\n",
      "Analyzing clause 2/5 (ID: unknown)\n",
      "Clause Text: The term (\"Term\") of this Agreement shall be for one hundred eighty days (180) from the date set forth below unless Network 1 or Visa or MasterCard or Harris Bank doesn't approve Affiliate's ISO application, in which case, the Term will be 3 years. This Agreement will automatically renew for successive one-year terms unless terminated by either party by providing the other with 30 days written notice that this Agreement will not be renewed or Affiliate enters into a Processing agreement with Network 1 and an ISO Sponsorship agreement with Harris Bank in which case this Agreement will automatically terminate concurrent with the execution of such agreements.\n",
      "Clause Category: Term and Renewal\n",
      "Analyzing compliance for clause ID 8b5ae85f-97cc-46a3-9f0c-0d678b18b715\n",
      "Checking statutory compliance against 9 statutes\n",
      "Validating statutory compliance for clause 8b5ae85f-97cc-46a3-9f0c-0d678b18b715 in Virginia jurisdiction\n",
      "Analyzing against 9 relevant statutes\n",
      "Identified 4 potential statutory issues\n",
      "ERROR: Error in statutory validation: 'str' object has no attribute 'get'\n",
      "Checking precedent compliance against 1 precedents\n",
      "Analyzing precedent compliance for clause 8b5ae85f-97cc-46a3-9f0c-0d678b18b715\n",
      "Analyzing against 1 precedents in Virginia jurisdiction\n",
      "Identified 0 potential precedent issues\n",
      "Found 0 valid precedent issues with confidence >= 0.75\n",
      "Found 0 precedent issues\n",
      "Checking consistency against 0 other clauses\n",
      "Starting contractual consistency check for 1 clauses (min_confidence=0.75)\n",
      "WARNING: Not enough clauses for consistency analysis\n",
      "Found 0 consistency issues\n",
      "Analyzing clause 3/5 (ID: unknown)\n",
      "Clause Text: Affiliate hereby agrees to indemnify and hold harmless Network 1, VISA, MasterCard and the Member Bank from and against any loss, cost or damage (including reasonable legal fees and court costs) incurred by Network 1, VISA, MasterCard and the Member Bank as a result of Affiliate's failure to comply with the terms of this Agreement, Affiliate's misrepresentation with respect to this Agreement or Affiliate's knowing or negligent misrepresentation with respect to Contractors.\n",
      "Clause Category: Indemnification\n",
      "Analyzing compliance for clause ID 2d4a252c-1db1-459a-9c50-7f3dc8c8c2a5\n",
      "Checking statutory compliance against 9 statutes\n",
      "Validating statutory compliance for clause 2d4a252c-1db1-459a-9c50-7f3dc8c8c2a5 in Virginia jurisdiction\n",
      "Analyzing against 9 relevant statutes\n",
      "Identified 4 potential statutory issues\n",
      "ERROR: Error in statutory validation: 'str' object has no attribute 'get'\n",
      "Checking precedent compliance against 1 precedents\n",
      "Analyzing precedent compliance for clause 2d4a252c-1db1-459a-9c50-7f3dc8c8c2a5\n",
      "Analyzing against 1 precedents in Virginia jurisdiction\n",
      "Identified 0 potential precedent issues\n",
      "Found 0 valid precedent issues with confidence >= 0.75\n",
      "Found 0 precedent issues\n",
      "Checking consistency against 0 other clauses\n",
      "Starting contractual consistency check for 1 clauses (min_confidence=0.75)\n",
      "WARNING: Not enough clauses for consistency analysis\n",
      "Found 0 consistency issues\n",
      "Analyzing clause 4/5 (ID: unknown)\n",
      "Clause Text: All disputes or claims hereunder shall be resolved by arbitration in McLean, Virginia, pursuant to the rules of the American Arbitration Association.\n",
      "Clause Category: Dispute Resolution\n",
      "Analyzing compliance for clause ID 3cc4b722-3c9c-489f-87b2-e896966cbb31\n",
      "Checking statutory compliance against 9 statutes\n",
      "Validating statutory compliance for clause 3cc4b722-3c9c-489f-87b2-e896966cbb31 in Virginia jurisdiction\n",
      "Analyzing against 9 relevant statutes\n",
      "Identified 4 potential statutory issues\n",
      "ERROR: Error in statutory validation: 'str' object has no attribute 'get'\n",
      "Checking precedent compliance against 1 precedents\n",
      "Analyzing precedent compliance for clause 3cc4b722-3c9c-489f-87b2-e896966cbb31\n",
      "Analyzing against 1 precedents in Virginia jurisdiction\n",
      "Identified 0 potential precedent issues\n",
      "Found 0 valid precedent issues with confidence >= 0.75\n",
      "Found 0 precedent issues\n",
      "Checking consistency against 0 other clauses\n",
      "Starting contractual consistency check for 1 clauses (min_confidence=0.75)\n",
      "WARNING: Not enough clauses for consistency analysis\n",
      "Found 0 consistency issues\n",
      "Analyzing clause 5/5 (ID: unknown)\n",
      "Clause Text: This agreement may be assigned or delegated, in whole or in part, by NETWORK 1 without the prior written consent of the other party herein. This agreement may not be assigned or delegated by Affiliate without prior written consent from Network 1. Such consent shall not be unreasonably withheld.\n",
      "Clause Category: Assignment\n",
      "Analyzing compliance for clause ID 1c0297b6-6153-45d6-b918-8ff16d2cf037\n",
      "Checking statutory compliance against 9 statutes\n",
      "Validating statutory compliance for clause 1c0297b6-6153-45d6-b918-8ff16d2cf037 in Virginia jurisdiction\n",
      "Analyzing against 9 relevant statutes\n",
      "Identified 4 potential statutory issues\n",
      "ERROR: Error in statutory validation: 'str' object has no attribute 'get'\n",
      "Checking precedent compliance against 1 precedents\n",
      "Analyzing precedent compliance for clause 1c0297b6-6153-45d6-b918-8ff16d2cf037\n",
      "Analyzing against 1 precedents in Virginia jurisdiction\n",
      "Identified 0 potential precedent issues\n",
      "Found 0 valid precedent issues with confidence >= 0.75\n",
      "Found 0 precedent issues\n",
      "Checking consistency against 0 other clauses\n",
      "Starting contractual consistency check for 1 clauses (min_confidence=0.75)\n",
      "WARNING: Not enough clauses for consistency analysis\n",
      "Found 0 consistency issues\n",
      "Stored document analysis in context bank: 0 non-compliant clauses with 0 issues\n",
      "Completed compliance check in 383.43 seconds. Found 0 non-compliant clauses\n",
      "[COMPLIANCE CHECKER] Compliance check completed with 0 results\n",
      "{'messages': [HumanMessage(content='You are given a file path the document which you must preprocess to extract clauses. Once the clauses are extracted, fetch all relevant knowledge related to it. Based on the collected knowledge, you should check for compliance of these clauses. Explain the non-compliant clauses, suggest changes and summarize the results for the User. FILE PATH OF DOCUMENT: \"./Original and Modified/modified_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf\" \",\\n            ', additional_kwargs={}, response_metadata={}, id='c9b1e78f-10a3-4517-ab9f-2add4ea0583f'), AIMessage(content='Okay, I understand the problem. I need to analyze the legal document at \"./Original and Modified/modified_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf\" for discrepancies and compliance issues. Here\\'s my plan:\\n\\n1.  **Status Check:** I\\'ll start by checking the status of the Pre Processor, Knowledge, Compliance Checker, and Post Processor agents to see if any of the tasks have already been completed.\\n2.  **Preprocess Document:** If the Pre Processor agent hasn\\'t processed the document yet, I\\'ll trigger it to extract and classify the clauses.\\n3.  **Retrieve Knowledge:** Once the preprocessing is complete, I\\'ll trigger the Knowledge Agent to retrieve relevant legal compliance knowledge from the web.\\n4.  **Check Compliance:** After the Knowledge Agent has retrieved the necessary information, I\\'ll trigger the Compliance Checker Agent to check the compliance of the clauses with legal regulations.\\n5.  **Summarize and Finalize:** Finally, after the compliance check is complete, I\\'ll trigger the Post Processor Agent to summarize the issues and finalize the output.\\n\\nHere\\'s the first step:', additional_kwargs={'function_call': {'name': 'transfer_to_pre_processor_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Planner Agent', id='run-1cd3d047-1377-4bf2-8daf-3a85a497a515-0', tool_calls=[{'name': 'transfer_to_pre_processor_agent', 'args': {}, 'id': '629a4b5a-3543-4190-8264-e6ec6196fb32', 'type': 'tool_call'}], usage_metadata={'input_tokens': 678, 'output_tokens': 281, 'total_tokens': 959, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to Pre Processor Agent', name='transfer_to_pre_processor_agent', id='0521108b-dd97-4862-95ce-d995eec41f48', tool_call_id='629a4b5a-3543-4190-8264-e6ec6196fb32'), AIMessage(content='Okay, I will now preprocess the document at the file path \"./Original and Modified/modified_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf\" to extract the full text, classify the document, identify named entities, and extract key clauses. After processing, I will store all the extracted information in a JSON object.', additional_kwargs={'function_call': {'name': 'preprocess_document_tool', 'arguments': '{\"file_path\": \"./Original and Modified/modified_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Pre Processor Agent', id='run-a3d0cac4-a1af-4642-abab-8c953ae7f67f-0', tool_calls=[{'name': 'preprocess_document_tool', 'args': {'file_path': './Original and Modified/modified_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf'}, 'id': '0ea1ea59-919b-48da-a545-02d8c097befd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 530, 'output_tokens': 164, 'total_tokens': 694, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='{\"Document Title\": \"Based on the provided text, the title of the document is:\\\\n\\\\n**NETWORK 1 FINANCIAL CORPORATION AFFILIATE OFFICE AGREEMENT**\", \"Document Class\": \"Legal Agreement - Affiliate Office Agreement\"}', name='preprocess_document_tool', id='1ecc1aa9-aa66-4b7c-a8d9-e6644f8c186d', tool_call_id='0ea1ea59-919b-48da-a545-02d8c097befd'), AIMessage(content='OK. I have preprocessed the document. Now I need to signal to the Planner Agent that I am done.', additional_kwargs={'function_call': {'name': 'transfer_to_planner_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Pre Processor Agent', id='run-28994fe4-c3d6-4e5c-ac09-98de4aac41a0-0', tool_calls=[{'name': 'transfer_to_planner_agent', 'args': {}, 'id': '44a89e11-b509-4628-90cc-a1edcf57dcd0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 633, 'output_tokens': 31, 'total_tokens': 664, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to Planner Agent', name='transfer_to_planner_agent', id='ea085e82-0d53-4182-87cb-380474a0c137', tool_call_id='44a89e11-b509-4628-90cc-a1edcf57dcd0'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'transfer_to_knowledge_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Planner Agent', id='run-cca9463d-7909-4c27-a33e-86300b41b8cf-0', tool_calls=[{'name': 'transfer_to_knowledge_agent', 'args': {}, 'id': '4a4f8f66-ba17-4c86-a825-615cb9032199', 'type': 'tool_call'}], usage_metadata={'input_tokens': 826, 'output_tokens': 7, 'total_tokens': 833, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to Knowledge Agent', name='transfer_to_knowledge_agent', id='020eefc5-893f-4edc-9b5f-da6661c3608d', tool_call_id='4a4f8f66-ba17-4c86-a825-615cb9032199'), AIMessage(content='Okay, I will start by retrieving knowledge related to \"Affiliate Office Agreements\" from government sources.', additional_kwargs={'function_call': {'name': 'retrieve_web_knowledge_tool', 'arguments': '{\"query\": \"site:govinfo.gov \\\\\"Affiliate Office Agreement\\\\\" AND \\\\\"Compliance\\\\\" AND (\\\\\"Regulations\\\\\" OR \\\\\"Statutes\\\\\") after:2020\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Knowledge Agent', id='run-7532f844-4018-44d1-ad60-b62061b7835d-0', tool_calls=[{'name': 'retrieve_web_knowledge_tool', 'args': {'query': 'site:govinfo.gov \"Affiliate Office Agreement\" AND \"Compliance\" AND (\"Regulations\" OR \"Statutes\") after:2020'}, 'id': 'ea470275-2d0e-40f1-98c0-816a7204f810', 'type': 'tool_call'}], usage_metadata={'input_tokens': 724, 'output_tokens': 59, 'total_tokens': 783, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='[{\"status\": \"knowledge search completed\", \"total_urls\": 10}]', name='retrieve_web_knowledge_tool', id='475a49c9-8cc7-4fa1-ad2d-43d543b08aa5', tool_call_id='ea470275-2d0e-40f1-98c0-816a7204f810'), AIMessage(content='Knowledge retrieval is completed.', additional_kwargs={'function_call': {'name': 'transfer_to_planner_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Knowledge Agent', id='run-b6dfe49f-d818-4ca0-b53d-df8d476a94a8-0', tool_calls=[{'name': 'transfer_to_planner_agent', 'args': {}, 'id': '0c976eb0-dda3-4f56-a856-ec8017e064d7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 779, 'output_tokens': 13, 'total_tokens': 792, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to Planner Agent', name='transfer_to_planner_agent', id='1feaa256-af05-4489-927a-f4e1831ffec3', tool_call_id='0c976eb0-dda3-4f56-a856-ec8017e064d7'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'transfer_to_compliance_checker_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Planner Agent', id='run-6a0505e0-5957-4bd9-8608-37d05d6e37b8-0', tool_calls=[{'name': 'transfer_to_compliance_checker_agent', 'args': {}, 'id': 'c2bbd3d1-a185-4606-a5cd-18f06132ea54', 'type': 'tool_call'}], usage_metadata={'input_tokens': 921, 'output_tokens': 9, 'total_tokens': 930, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to Compliance Checker Agent', name='transfer_to_compliance_checker_agent', id='898fd3af-50e3-4f65-98a9-5b8017aace7b', tool_call_id='c2bbd3d1-a185-4606-a5cd-18f06132ea54'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'check_knowledge_relevance_tool', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Compliance Checker Agent', id='run-1b18551c-f269-45d7-93ca-06d2cd7a8758-0', tool_calls=[{'name': 'check_knowledge_relevance_tool', 'args': {}, 'id': 'ae25ec2e-bb65-4abf-a548-efe571dfd136', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1470, 'output_tokens': 7, 'total_tokens': 1477, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Affiliate Office Agreement, Contractor Obligations, Merchant Agreements, Payment Processing Services, ISO Sponsorship, Termination Conditions, Indemnification, Restrictions on Affiliate, Compensation, Independent Contractor Status, Dispute Resolution, Use of Network 1 Name, Equipment Purchase and Lease, Term and Renewal, Assignment, Governing Law', name='check_knowledge_relevance_tool', id='49ab4eb4-6f2b-4ee2-be11-5241484f28b3', tool_call_id='ae25ec2e-bb65-4abf-a548-efe571dfd136'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'transfer_to_knowledge_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Compliance Checker Agent', id='run-c2b7de3a-8e60-49ac-bfe9-238fac46b0bd-0', tool_calls=[{'name': 'transfer_to_knowledge_agent', 'args': {}, 'id': 'c32b283a-b702-448e-bd66-806d0460b3f2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1542, 'output_tokens': 7, 'total_tokens': 1549, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to Knowledge Agent', name='transfer_to_knowledge_agent', id='18c00bf7-0b1b-4b60-b26c-ea16eafa73d7', tool_call_id='c32b283a-b702-448e-bd66-806d0460b3f2'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'retrieve_web_knowledge_tool', 'arguments': '{\"query\": \"site:ecfr.gov \\\\\"Independent Contractor Status\\\\\" AND \\\\\"Regulations\\\\\" AND (\\\\\"IRS guidelines\\\\\" OR \\\\\"Labor laws\\\\\") after:2020\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Knowledge Agent', id='run-761bcabb-71f3-412f-8643-8f47e8d04d2e-0', tool_calls=[{'name': 'retrieve_web_knowledge_tool', 'args': {'query': 'site:ecfr.gov \"Independent Contractor Status\" AND \"Regulations\" AND (\"IRS guidelines\" OR \"Labor laws\") after:2020'}, 'id': '7d953df2-cb96-4790-aaee-5347c8176f3a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 916, 'output_tokens': 39, 'total_tokens': 955, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='[{\"status\": \"knowledge search completed\", \"total_urls\": 0}]', name='retrieve_web_knowledge_tool', id='ba1bdeb7-f4c7-48e4-a2c2-d8c5026e7418', tool_call_id='7d953df2-cb96-4790-aaee-5347c8176f3a'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'retrieve_web_knowledge_tool', 'arguments': '{\"query\": \"site:irs.gov \\\\\"Independent Contractor Status\\\\\" AND \\\\\"Regulations\\\\\" AND (\\\\\"IRS guidelines\\\\\" OR \\\\\"Labor laws\\\\\") after:2020\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Knowledge Agent', id='run-ac3e51a5-4925-4d1a-a2cd-fede298d6f43-0', tool_calls=[{'name': 'retrieve_web_knowledge_tool', 'args': {'query': 'site:irs.gov \"Independent Contractor Status\" AND \"Regulations\" AND (\"IRS guidelines\" OR \"Labor laws\") after:2020'}, 'id': '328ed8a0-3bef-4705-9fc2-b91a42c94865', 'type': 'tool_call'}], usage_metadata={'input_tokens': 971, 'output_tokens': 38, 'total_tokens': 1009, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='[{\"status\": \"knowledge search completed\", \"total_urls\": 0}]', name='retrieve_web_knowledge_tool', id='e0b6c6f1-4e5c-498d-b99e-52c63e76df76', tool_call_id='328ed8a0-3bef-4705-9fc2-b91a42c94865'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'retrieve_web_knowledge_tool', 'arguments': '{\"query\": \"site:dol.gov \\\\\"Independent Contractor Status\\\\\" AND \\\\\"Regulations\\\\\" AND (\\\\\"IRS guidelines\\\\\" OR \\\\\"Labor laws\\\\\") after:2020\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Knowledge Agent', id='run-96363b44-ba63-4799-9d9a-108d8aae3c1c-0', tool_calls=[{'name': 'retrieve_web_knowledge_tool', 'args': {'query': 'site:dol.gov \"Independent Contractor Status\" AND \"Regulations\" AND (\"IRS guidelines\" OR \"Labor laws\") after:2020'}, 'id': '5730bf32-4b17-4a2f-b8e2-371d801519e1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1025, 'output_tokens': 38, 'total_tokens': 1063, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='[{\"status\": \"knowledge search completed\", \"total_urls\": 2}]', name='retrieve_web_knowledge_tool', id='76bc1801-bb01-439a-ae5e-9af85b4e9ad8', tool_call_id='5730bf32-4b17-4a2f-b8e2-371d801519e1'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'transfer_to_planner_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Knowledge Agent', id='run-5ec077b3-e8a2-4b22-a474-8ed32d2be9e5-0', tool_calls=[{'name': 'transfer_to_planner_agent', 'args': {}, 'id': 'b13c9611-18f4-42c1-9ff5-893298e23eb2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1079, 'output_tokens': 7, 'total_tokens': 1086, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to Planner Agent', name='transfer_to_planner_agent', id='43207ddb-48f7-4877-8e06-14c04d297859', tool_call_id='b13c9611-18f4-42c1-9ff5-893298e23eb2'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'transfer_to_compliance_checker_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Planner Agent', id='run-0cb0f15c-b306-4d78-bcea-645c2375dab6-0', tool_calls=[{'name': 'transfer_to_compliance_checker_agent', 'args': {}, 'id': 'b32545ef-c56a-4b8d-abf3-f7d0a6c0207d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1221, 'output_tokens': 9, 'total_tokens': 1230, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to Compliance Checker Agent', name='transfer_to_compliance_checker_agent', id='e9095af3-89ad-49bf-a09b-6df1f2e7e407', tool_call_id='b32545ef-c56a-4b8d-abf3-f7d0a6c0207d'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'compliance_check_tool', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Compliance Checker Agent', id='run-0da06eea-65ec-4499-aa5a-3bfe1289f076-0', tool_calls=[{'name': 'compliance_check_tool', 'args': {}, 'id': 'd1596887-8f6a-48ed-a5c3-93d707cf7333', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1770, 'output_tokens': 5, 'total_tokens': 1775, 'input_token_details': {'cache_read': 0}}), ToolMessage(content=[], name='compliance_check_tool', id='81398feb-0ca9-4ce4-b8b1-658021cd2c1d', tool_call_id='d1596887-8f6a-48ed-a5c3-93d707cf7333'), AIMessage(content='Based on the compliance check, no non-compliant clauses were found.', additional_kwargs={'function_call': {'name': 'transfer_to_planner_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Compliance Checker Agent', id='run-0eb31247-ff56-4637-baf7-f84ed13a6ec1-0', tool_calls=[{'name': 'transfer_to_planner_agent', 'args': {}, 'id': '210098ec-8d51-42a8-814f-8dfdfbfcdc66', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1781, 'output_tokens': 22, 'total_tokens': 1803, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to Planner Agent', name='transfer_to_planner_agent', id='93948a2a-f9ea-4626-92d4-a401ea9e6393', tool_call_id='210098ec-8d51-42a8-814f-8dfdfbfcdc66'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'transfer_to_post_processor_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Planner Agent', id='run-4b285376-145b-4818-bdf3-515f50acf255-0', tool_calls=[{'name': 'transfer_to_post_processor_agent', 'args': {}, 'id': '7a7a0773-956e-48e5-b46b-3573f8fabb48', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1277, 'output_tokens': 9, 'total_tokens': 1286, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to Post Processor Agent', name='transfer_to_post_processor_agent', id='c6f84b2f-8a71-48a5-88ac-eb432c4cebde', tool_call_id='7a7a0773-956e-48e5-b46b-3573f8fabb48'), AIMessage(content='I have completed the compliance checks and there were no non-compliant clauses. I will now summarize the document.', additional_kwargs={'function_call': {'name': 'transfer_to_planner_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='Post Processor Agent', id='run-314e8dcd-9b37-42df-b4b4-5f96e387295c-0', tool_calls=[{'name': 'transfer_to_planner_agent', 'args': {}, 'id': '52b3555e-8fb9-4fff-a9c3-7179892c9121', 'type': 'tool_call'}], usage_metadata={'input_tokens': 945, 'output_tokens': 30, 'total_tokens': 975, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to Planner Agent', name='transfer_to_planner_agent', id='f827204f-ce5a-4b04-9911-4e2fe66051f3', tool_call_id='52b3555e-8fb9-4fff-a9c3-7179892c9121'), AIMessage(content='', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'MALFORMED_FUNCTION_CALL', 'safety_ratings': []}, name='Planner Agent', id='run-ea3eb8a6-c168-480d-9aec-09f444ceb23b-0', usage_metadata={'input_tokens': 1322, 'output_tokens': 0, 'total_tokens': 1322, 'input_token_details': {'cache_read': 0}})], 'active_agent': 'Planner Agent'}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "turn_1 = app.invoke(\n",
    "    {\"messages\": \n",
    "        [{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"\"\"You are given a file path the document which you must preprocess to extract clauses. Once the clauses are extracted, fetch all relevant knowledge related to it. Based on the collected knowledge, you should check for compliance of these clauses. Explain the non-compliant clauses, suggest changes and summarize the results for the User. FILE PATH OF DOCUMENT: \\\"./Original and Modified/modified_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf\\\" \",\n",
    "            \"\"\"\n",
    "        }]\n",
    "    },\n",
    "    config,\n",
    ")\n",
    "print(turn_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legal-lm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
